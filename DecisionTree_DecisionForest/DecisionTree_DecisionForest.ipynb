{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "cf032bb7-df8e-45a9-8b61-9653d0c1bb79",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pyspark\n",
    "from pyspark.sql import SparkSession"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "6ed50196-adb3-4d7f-9bc4-098f91c51e60",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "23/12/30 19:26:58 WARN Utils: Your hostname, quangtn933.local resolves to a loopback address: 127.0.0.1; using 192.168.1.90 instead (on interface en0)\n",
      "23/12/30 19:26:58 WARN Utils: Set SPARK_LOCAL_IP if you need to bind to another address\n",
      "Setting default log level to \"WARN\".\n",
      "To adjust logging level use sc.setLogLevel(newLevel). For SparkR, use setLogLevel(newLevel).\n",
      "23/12/30 19:26:58 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable\n"
     ]
    }
   ],
   "source": [
    "spark = SparkSession.builder.config(\"spark.driver.memory\", \"8g\").appName(\"chapter4\").getOrCreate()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "74a42c0a-bd59-48d2-82b0-5a8fc3fe5e7f",
   "metadata": {},
   "source": [
    "## Getting data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "972dbb49-8c37-4e57-a65d-2fd59e0b82c3",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "23/12/30 19:27:15 WARN GarbageCollectionMetrics: To enable non-built-in garbage collector(s) List(G1 Concurrent GC), users should configure it(them) to spark.eventLog.gcMetrics.youngGenerationGarbageCollectors or spark.eventLog.gcMetrics.oldGenerationGarbageCollectors\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- _c0: integer (nullable = true)\n",
      " |-- _c1: integer (nullable = true)\n",
      " |-- _c2: integer (nullable = true)\n",
      " |-- _c3: integer (nullable = true)\n",
      " |-- _c4: integer (nullable = true)\n",
      " |-- _c5: integer (nullable = true)\n",
      " |-- _c6: integer (nullable = true)\n",
      " |-- _c7: integer (nullable = true)\n",
      " |-- _c8: integer (nullable = true)\n",
      " |-- _c9: integer (nullable = true)\n",
      " |-- _c10: integer (nullable = true)\n",
      " |-- _c11: integer (nullable = true)\n",
      " |-- _c12: integer (nullable = true)\n",
      " |-- _c13: integer (nullable = true)\n",
      " |-- _c14: integer (nullable = true)\n",
      " |-- _c15: integer (nullable = true)\n",
      " |-- _c16: integer (nullable = true)\n",
      " |-- _c17: integer (nullable = true)\n",
      " |-- _c18: integer (nullable = true)\n",
      " |-- _c19: integer (nullable = true)\n",
      " |-- _c20: integer (nullable = true)\n",
      " |-- _c21: integer (nullable = true)\n",
      " |-- _c22: integer (nullable = true)\n",
      " |-- _c23: integer (nullable = true)\n",
      " |-- _c24: integer (nullable = true)\n",
      " |-- _c25: integer (nullable = true)\n",
      " |-- _c26: integer (nullable = true)\n",
      " |-- _c27: integer (nullable = true)\n",
      " |-- _c28: integer (nullable = true)\n",
      " |-- _c29: integer (nullable = true)\n",
      " |-- _c30: integer (nullable = true)\n",
      " |-- _c31: integer (nullable = true)\n",
      " |-- _c32: integer (nullable = true)\n",
      " |-- _c33: integer (nullable = true)\n",
      " |-- _c34: integer (nullable = true)\n",
      " |-- _c35: integer (nullable = true)\n",
      " |-- _c36: integer (nullable = true)\n",
      " |-- _c37: integer (nullable = true)\n",
      " |-- _c38: integer (nullable = true)\n",
      " |-- _c39: integer (nullable = true)\n",
      " |-- _c40: integer (nullable = true)\n",
      " |-- _c41: integer (nullable = true)\n",
      " |-- _c42: integer (nullable = true)\n",
      " |-- _c43: integer (nullable = true)\n",
      " |-- _c44: integer (nullable = true)\n",
      " |-- _c45: integer (nullable = true)\n",
      " |-- _c46: integer (nullable = true)\n",
      " |-- _c47: integer (nullable = true)\n",
      " |-- _c48: integer (nullable = true)\n",
      " |-- _c49: integer (nullable = true)\n",
      " |-- _c50: integer (nullable = true)\n",
      " |-- _c51: integer (nullable = true)\n",
      " |-- _c52: integer (nullable = true)\n",
      " |-- _c53: integer (nullable = true)\n",
      " |-- _c54: integer (nullable = true)\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "data_without_header = spark.read.option(\"inferSchema\", True).option(\"header\", False).csv(\"./covtype.data\")\n",
    "data_without_header.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "d38cd3e6-72f6-4aa6-8cdb-2cd23cc415f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql.types import DoubleType\n",
    "from pyspark.sql.functions import col\n",
    "\n",
    "colnames = [\"Elevation\", \"Aspect\", \"Slope\", \"Horizontal_Distance_To_Hydrology\", \"Vertical_Distance_To_Hydrology\", \\\n",
    "            \"Horizontal_Distance_To_Roadways\", \"Hillshade_9am\", \"Hillshade_Noon\", \"Hillshade_3pm\", \\\n",
    "            \"Horizontal_Distance_To_Fire_Points\"] + [f\"Wilderness_Area_{i}\" for i in range(4)] \\\n",
    "            + [f\"Soild_Type_{i}\" for i in range(40)] + [\"Cover_Type\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "c8a734da-2dee-4792-9471-7963fc321f2a",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = data_without_header.toDF(*colnames).withColumn(\"Cover_Type\", col(\"Cover_Type\").cast(DoubleType()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "1970316a-8b4e-4826-869f-1178245fd8e9",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "23/12/30 16:38:39 WARN SparkStringUtils: Truncated the string representation of a plan since it was too large. This behavior can be adjusted by setting 'spark.sql.debug.maxToStringFields'.\n",
      "                                                                                \r"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Row(Elevation=2596, Aspect=51, Slope=3, Horizontal_Distance_To_Hydrology=258, Vertical_Distance_To_Hydrology=0, Horizontal_Distance_To_Roadways=510, Hillshade_9am=221, Hillshade_Noon=232, Hillshade_3pm=148, Horizontal_Distance_To_Fire_Points=6279, Wilderness_Area_0=1, Wilderness_Area_1=0, Wilderness_Area_2=0, Wilderness_Area_3=0, Soild_Type_0=0, Soild_Type_1=0, Soild_Type_2=0, Soild_Type_3=0, Soild_Type_4=0, Soild_Type_5=0, Soild_Type_6=0, Soild_Type_7=0, Soild_Type_8=0, Soild_Type_9=0, Soild_Type_10=0, Soild_Type_11=0, Soild_Type_12=0, Soild_Type_13=0, Soild_Type_14=0, Soild_Type_15=0, Soild_Type_16=0, Soild_Type_17=0, Soild_Type_18=0, Soild_Type_19=0, Soild_Type_20=0, Soild_Type_21=0, Soild_Type_22=0, Soild_Type_23=0, Soild_Type_24=0, Soild_Type_25=0, Soild_Type_26=0, Soild_Type_27=0, Soild_Type_28=1, Soild_Type_29=0, Soild_Type_30=0, Soild_Type_31=0, Soild_Type_32=0, Soild_Type_33=0, Soild_Type_34=0, Soild_Type_35=0, Soild_Type_36=0, Soild_Type_37=0, Soild_Type_38=0, Soild_Type_39=0, Cover_Type=5.0)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "d711cb75-f79e-40ef-9a9b-1c701465509a",
   "metadata": {},
   "outputs": [],
   "source": [
    "(train_data, test_data) = data.randomSplit([0.9, 0.1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "ca3f562d-a06a-4fc7-bcc9-686df8f34a39",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "23/12/30 19:27:36 WARN SparkStringUtils: Truncated the string representation of a plan since it was too large. This behavior can be adjusted by setting 'spark.sql.debug.maxToStringFields'.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "DataFrame[Elevation: int, Aspect: int, Slope: int, Horizontal_Distance_To_Hydrology: int, Vertical_Distance_To_Hydrology: int, Horizontal_Distance_To_Roadways: int, Hillshade_9am: int, Hillshade_Noon: int, Hillshade_3pm: int, Horizontal_Distance_To_Fire_Points: int, Wilderness_Area_0: int, Wilderness_Area_1: int, Wilderness_Area_2: int, Wilderness_Area_3: int, Soild_Type_0: int, Soild_Type_1: int, Soild_Type_2: int, Soild_Type_3: int, Soild_Type_4: int, Soild_Type_5: int, Soild_Type_6: int, Soild_Type_7: int, Soild_Type_8: int, Soild_Type_9: int, Soild_Type_10: int, Soild_Type_11: int, Soild_Type_12: int, Soild_Type_13: int, Soild_Type_14: int, Soild_Type_15: int, Soild_Type_16: int, Soild_Type_17: int, Soild_Type_18: int, Soild_Type_19: int, Soild_Type_20: int, Soild_Type_21: int, Soild_Type_22: int, Soild_Type_23: int, Soild_Type_24: int, Soild_Type_25: int, Soild_Type_26: int, Soild_Type_27: int, Soild_Type_28: int, Soild_Type_29: int, Soild_Type_30: int, Soild_Type_31: int, Soild_Type_32: int, Soild_Type_33: int, Soild_Type_34: int, Soild_Type_35: int, Soild_Type_36: int, Soild_Type_37: int, Soild_Type_38: int, Soild_Type_39: int, Cover_Type: double]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data.cache()\n",
    "test_data.cache()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "7c9c4bb1-2834-4a94-bf03-071b384a40d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.ml.feature import VectorAssembler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "ef5c3971-6f9a-4a78-b49a-43b6f5ee8842",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "54 <built-in method count of list object at 0x7fb8b8cf2d80>\n"
     ]
    }
   ],
   "source": [
    "input_cols = colnames[:-1]\n",
    "print(len(input_cols), input_cols.count)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "0236ecce-78cf-4c5a-a2e7-f07712b084ce",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Elevation',\n",
       " 'Aspect',\n",
       " 'Slope',\n",
       " 'Horizontal_Distance_To_Hydrology',\n",
       " 'Vertical_Distance_To_Hydrology',\n",
       " 'Horizontal_Distance_To_Roadways',\n",
       " 'Hillshade_9am',\n",
       " 'Hillshade_Noon',\n",
       " 'Hillshade_3pm',\n",
       " 'Horizontal_Distance_To_Fire_Points',\n",
       " 'Wilderness_Area_0',\n",
       " 'Wilderness_Area_1',\n",
       " 'Wilderness_Area_2',\n",
       " 'Wilderness_Area_3',\n",
       " 'Soild_Type_0',\n",
       " 'Soild_Type_1',\n",
       " 'Soild_Type_2',\n",
       " 'Soild_Type_3',\n",
       " 'Soild_Type_4',\n",
       " 'Soild_Type_5',\n",
       " 'Soild_Type_6',\n",
       " 'Soild_Type_7',\n",
       " 'Soild_Type_8',\n",
       " 'Soild_Type_9',\n",
       " 'Soild_Type_10',\n",
       " 'Soild_Type_11',\n",
       " 'Soild_Type_12',\n",
       " 'Soild_Type_13',\n",
       " 'Soild_Type_14',\n",
       " 'Soild_Type_15',\n",
       " 'Soild_Type_16',\n",
       " 'Soild_Type_17',\n",
       " 'Soild_Type_18',\n",
       " 'Soild_Type_19',\n",
       " 'Soild_Type_20',\n",
       " 'Soild_Type_21',\n",
       " 'Soild_Type_22',\n",
       " 'Soild_Type_23',\n",
       " 'Soild_Type_24',\n",
       " 'Soild_Type_25',\n",
       " 'Soild_Type_26',\n",
       " 'Soild_Type_27',\n",
       " 'Soild_Type_28',\n",
       " 'Soild_Type_29',\n",
       " 'Soild_Type_30',\n",
       " 'Soild_Type_31',\n",
       " 'Soild_Type_32',\n",
       " 'Soild_Type_33',\n",
       " 'Soild_Type_34',\n",
       " 'Soild_Type_35',\n",
       " 'Soild_Type_36',\n",
       " 'Soild_Type_37',\n",
       " 'Soild_Type_38',\n",
       " 'Soild_Type_39']"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "input_cols"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "dd89fb34-a4fe-462e-ae22-975f42887991",
   "metadata": {},
   "outputs": [],
   "source": [
    "vector_assembler = VectorAssembler(inputCols=input_cols, outputCol=\"featureVector\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "d050108b-fa52-4350-ad80-855afbc16fbf",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 3:>                                                          (0 + 1) / 1]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----------------------------------------------------------------------------------------------------+\n",
      "|featureVector                                                                                        |\n",
      "+-----------------------------------------------------------------------------------------------------+\n",
      "|(54,[0,1,2,3,4,5,6,7,8,9,13,15],[1863.0,37.0,17.0,120.0,18.0,90.0,217.0,202.0,115.0,769.0,1.0,1.0])  |\n",
      "|(54,[0,1,2,5,6,7,8,9,13,18],[1874.0,18.0,14.0,90.0,208.0,209.0,135.0,793.0,1.0,1.0])                 |\n",
      "|(54,[0,1,2,3,4,5,6,7,8,9,13,15],[1888.0,33.0,22.0,150.0,46.0,108.0,209.0,185.0,103.0,735.0,1.0,1.0]) |\n",
      "|(54,[0,1,2,3,4,5,6,7,8,9,13,14],[1889.0,28.0,22.0,150.0,23.0,120.0,205.0,185.0,108.0,759.0,1.0,1.0]) |\n",
      "|(54,[0,1,2,3,4,5,6,7,8,9,13,18],[1889.0,353.0,30.0,95.0,39.0,67.0,153.0,172.0,146.0,600.0,1.0,1.0])  |\n",
      "|(54,[0,1,2,3,4,5,6,7,8,9,13,18],[1896.0,337.0,12.0,30.0,6.0,175.0,195.0,224.0,168.0,732.0,1.0,1.0])  |\n",
      "|(54,[0,1,2,3,4,5,6,7,8,9,13,15],[1898.0,34.0,23.0,175.0,56.0,134.0,210.0,184.0,99.0,765.0,1.0,1.0])  |\n",
      "|(54,[0,1,2,3,4,5,6,7,8,9,13,18],[1899.0,355.0,22.0,153.0,43.0,124.0,178.0,195.0,151.0,819.0,1.0,1.0])|\n",
      "|(54,[0,1,2,3,4,5,6,7,8,9,13,14],[1901.0,311.0,9.0,30.0,2.0,190.0,195.0,234.0,179.0,726.0,1.0,1.0])   |\n",
      "|(54,[0,1,2,3,4,5,6,7,8,9,13,14],[1903.0,5.0,13.0,42.0,4.0,201.0,203.0,214.0,148.0,708.0,1.0,1.0])    |\n",
      "|(54,[0,1,2,3,4,5,6,7,8,9,13,14],[1904.0,51.0,26.0,67.0,30.0,162.0,222.0,175.0,72.0,711.0,1.0,1.0])   |\n",
      "|(54,[0,1,2,3,4,5,6,7,8,9,13,18],[1905.0,19.0,27.0,134.0,58.0,120.0,188.0,171.0,108.0,636.0,1.0,1.0]) |\n",
      "|(54,[0,1,2,3,4,5,6,7,8,9,13,14],[1905.0,33.0,27.0,90.0,46.0,150.0,204.0,171.0,89.0,725.0,1.0,1.0])   |\n",
      "|(54,[0,1,2,3,4,5,6,7,8,9,13,16],[1905.0,77.0,21.0,90.0,38.0,120.0,241.0,196.0,75.0,1025.0,1.0,1.0])  |\n",
      "|(54,[0,1,2,3,4,5,6,7,8,9,13,15],[1906.0,356.0,20.0,150.0,55.0,120.0,184.0,201.0,151.0,726.0,1.0,1.0])|\n",
      "|(54,[0,1,2,3,4,5,6,7,8,9,13,18],[1908.0,323.0,32.0,150.0,52.0,120.0,125.0,190.0,196.0,765.0,1.0,1.0])|\n",
      "|(54,[0,1,2,3,4,5,6,7,8,9,13,15],[1916.0,24.0,25.0,212.0,74.0,175.0,197.0,177.0,105.0,789.0,1.0,1.0]) |\n",
      "|(54,[0,1,2,3,4,5,6,7,8,9,13,18],[1916.0,320.0,24.0,190.0,60.0,162.0,151.0,210.0,195.0,832.0,1.0,1.0])|\n",
      "|(54,[0,1,2,3,4,5,6,7,8,9,13,23],[1918.0,321.0,28.0,42.0,17.0,85.0,139.0,201.0,196.0,402.0,1.0,1.0])  |\n",
      "|(54,[0,1,2,3,4,5,6,7,8,9,13,14],[1919.0,30.0,22.0,67.0,9.0,256.0,208.0,188.0,107.0,661.0,1.0,1.0])   |\n",
      "+-----------------------------------------------------------------------------------------------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "assembled_train_data = vector_assembler.transform(train_data)\n",
    "assembled_train_data.select(\"featureVector\").show(truncate=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "96da17c5-caf4-42d3-83e4-4b61f476e7ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.ml.classification import DecisionTreeClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "b58c3f63-570f-438d-bc2a-268bdd723ba1",
   "metadata": {},
   "outputs": [],
   "source": [
    "classifier = DecisionTreeClassifier(seed=1234, labelCol=\"Cover_Type\", featuresCol=\"featureVector\", \\\n",
    "                predictionCol=\"prediction\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "eabee036-490c-4aa2-879b-f70af596c58b",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DecisionTreeClassificationModel: uid=DecisionTreeClassifier_598c49fddac8, depth=5, numNodes=45, numClasses=8, numFeatures=54\n",
      "  If (feature 0 <= 3036.5)\n",
      "   If (feature 0 <= 2545.5)\n",
      "    If (feature 10 <= 0.5)\n",
      "     If (feature 0 <= 2414.0)\n",
      "      If (feature 3 <= 15.0)\n",
      "       Predict: 4.0\n",
      "      Else (feature 3 > 15.0)\n",
      "       Predict: 3.0\n",
      "     Else (feature 0 > 2414.0)\n",
      "      Predict: 3.0\n",
      "    Else (feature 10 > 0.5)\n",
      "     If (feature 9 <= 5482.0)\n",
      "      Predict: 2.0\n",
      "     Else (feature 9 > 5482.0)\n",
      "      If (feature 5 <= 540.5)\n",
      "       Predict: 2.0\n",
      "      Else (feature 5 > 540.5)\n",
      "       Predict: 5.0\n",
      "   Else (feature 0 > 2545.5)\n",
      "    If (feature 15 <= 0.5)\n",
      "     If (feature 17 <= 0.5)\n",
      "      Predict: 2.0\n",
      "     Else (feature 17 > 0.5)\n",
      "      If (feature 0 <= 2678.5)\n",
      "       Predict: 3.0\n",
      "      Else (feature 0 > 2678.5)\n",
      "       Predict: 2.0\n",
      "    Else (feature 15 > 0.5)\n",
      "     If (feature 9 <= 1413.5)\n",
      "      If (feature 7 <= 216.5)\n",
      "       Predict: 2.0\n",
      "      Else (feature 7 > 216.5)\n",
      "       Predict: 3.0\n",
      "     Else (feature 9 > 1413.5)\n",
      "      If (feature 5 <= 2268.5)\n",
      "       Predict: 3.0\n",
      "      Else (feature 5 > 2268.5)\n",
      "       Predict: 2.0\n",
      "  Else (feature 0 > 3036.5)\n",
      "   If (feature 0 <= 3315.5)\n",
      "    If (feature 7 <= 239.5)\n",
      "     Predict: 1.0\n",
      "    Else (feature 7 > 239.5)\n",
      "     If (feature 3 <= 333.0)\n",
      "      Predict: 1.0\n",
      "     Else (feature 3 > 333.0)\n",
      "      If (feature 0 <= 3207.5)\n",
      "       Predict: 2.0\n",
      "      Else (feature 0 > 3207.5)\n",
      "       Predict: 1.0\n",
      "   Else (feature 0 > 3315.5)\n",
      "    If (feature 12 <= 0.5)\n",
      "     If (feature 3 <= 296.0)\n",
      "      If (feature 6 <= 206.5)\n",
      "       Predict: 1.0\n",
      "      Else (feature 6 > 206.5)\n",
      "       Predict: 7.0\n",
      "     Else (feature 3 > 296.0)\n",
      "      Predict: 1.0\n",
      "    Else (feature 12 > 0.5)\n",
      "     If (feature 45 <= 0.5)\n",
      "      Predict: 7.0\n",
      "     Else (feature 45 > 0.5)\n",
      "      If (feature 5 <= 978.0)\n",
      "       Predict: 7.0\n",
      "      Else (feature 5 > 978.0)\n",
      "       Predict: 1.0\n",
      "\n"
     ]
    }
   ],
   "source": [
    "model = classifier.fit(assembled_train_data)\n",
    "print(model.toDebugString)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "8af5a5c4-d258-4338-b20a-e638b71a8949",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "15b06765-a8b0-4621-ad19-7bf3cb56fef7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>importance</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Elevation</th>\n",
       "      <td>0.826586</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Soild_Type_1</th>\n",
       "      <td>0.028615</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Hillshade_Noon</th>\n",
       "      <td>0.028467</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Soild_Type_3</th>\n",
       "      <td>0.026704</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Horizontal_Distance_To_Hydrology</th>\n",
       "      <td>0.025432</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Wilderness_Area_0</th>\n",
       "      <td>0.024403</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Soild_Type_31</th>\n",
       "      <td>0.018321</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Wilderness_Area_2</th>\n",
       "      <td>0.012394</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Horizontal_Distance_To_Roadways</th>\n",
       "      <td>0.003988</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Hillshade_9am</th>\n",
       "      <td>0.002721</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Horizontal_Distance_To_Fire_Points</th>\n",
       "      <td>0.002369</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Soild_Type_38</th>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Soild_Type_25</th>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Soild_Type_26</th>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Soild_Type_22</th>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Soild_Type_24</th>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Soild_Type_23</th>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Soild_Type_28</th>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Soild_Type_21</th>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Soild_Type_20</th>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Soild_Type_27</th>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Soild_Type_32</th>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Soild_Type_29</th>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Soild_Type_30</th>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Soild_Type_18</th>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Soild_Type_33</th>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Soild_Type_34</th>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Soild_Type_35</th>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Soild_Type_36</th>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Soild_Type_37</th>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Soild_Type_19</th>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Soild_Type_13</th>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Soild_Type_17</th>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Soild_Type_16</th>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Slope</th>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Vertical_Distance_To_Hydrology</th>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Hillshade_3pm</th>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Wilderness_Area_1</th>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Wilderness_Area_3</th>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Soild_Type_0</th>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Soild_Type_2</th>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Soild_Type_4</th>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Soild_Type_5</th>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Soild_Type_6</th>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Soild_Type_7</th>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Soild_Type_8</th>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Soild_Type_9</th>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Soild_Type_10</th>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Soild_Type_11</th>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Soild_Type_12</th>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Aspect</th>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Soild_Type_14</th>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Soild_Type_15</th>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Soild_Type_39</th>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                    importance\n",
       "Elevation                             0.826586\n",
       "Soild_Type_1                          0.028615\n",
       "Hillshade_Noon                        0.028467\n",
       "Soild_Type_3                          0.026704\n",
       "Horizontal_Distance_To_Hydrology      0.025432\n",
       "Wilderness_Area_0                     0.024403\n",
       "Soild_Type_31                         0.018321\n",
       "Wilderness_Area_2                     0.012394\n",
       "Horizontal_Distance_To_Roadways       0.003988\n",
       "Hillshade_9am                         0.002721\n",
       "Horizontal_Distance_To_Fire_Points    0.002369\n",
       "Soild_Type_38                         0.000000\n",
       "Soild_Type_25                         0.000000\n",
       "Soild_Type_26                         0.000000\n",
       "Soild_Type_22                         0.000000\n",
       "Soild_Type_24                         0.000000\n",
       "Soild_Type_23                         0.000000\n",
       "Soild_Type_28                         0.000000\n",
       "Soild_Type_21                         0.000000\n",
       "Soild_Type_20                         0.000000\n",
       "Soild_Type_27                         0.000000\n",
       "Soild_Type_32                         0.000000\n",
       "Soild_Type_29                         0.000000\n",
       "Soild_Type_30                         0.000000\n",
       "Soild_Type_18                         0.000000\n",
       "Soild_Type_33                         0.000000\n",
       "Soild_Type_34                         0.000000\n",
       "Soild_Type_35                         0.000000\n",
       "Soild_Type_36                         0.000000\n",
       "Soild_Type_37                         0.000000\n",
       "Soild_Type_19                         0.000000\n",
       "Soild_Type_13                         0.000000\n",
       "Soild_Type_17                         0.000000\n",
       "Soild_Type_16                         0.000000\n",
       "Slope                                 0.000000\n",
       "Vertical_Distance_To_Hydrology        0.000000\n",
       "Hillshade_3pm                         0.000000\n",
       "Wilderness_Area_1                     0.000000\n",
       "Wilderness_Area_3                     0.000000\n",
       "Soild_Type_0                          0.000000\n",
       "Soild_Type_2                          0.000000\n",
       "Soild_Type_4                          0.000000\n",
       "Soild_Type_5                          0.000000\n",
       "Soild_Type_6                          0.000000\n",
       "Soild_Type_7                          0.000000\n",
       "Soild_Type_8                          0.000000\n",
       "Soild_Type_9                          0.000000\n",
       "Soild_Type_10                         0.000000\n",
       "Soild_Type_11                         0.000000\n",
       "Soild_Type_12                         0.000000\n",
       "Aspect                                0.000000\n",
       "Soild_Type_14                         0.000000\n",
       "Soild_Type_15                         0.000000\n",
       "Soild_Type_39                         0.000000"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.DataFrame(model.featureImportances.toArray(), index=input_cols, \\\n",
    "        columns=['importance']). \\\n",
    "        sort_values(by=\"importance\", ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "24a478d3-b85f-4967-a871-016ecb40f35b",
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions = model.transform(assembled_train_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "056be05f-3fe6-4385-8ccc-6045ea59badf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------+----------+-------------------------------------------------------------------------------------------------+\n",
      "|Cover_Type|prediction|probability                                                                                      |\n",
      "+----------+----------+-------------------------------------------------------------------------------------------------+\n",
      "|6.0       |3.0       |[0.0,0.0,0.02519171931497596,0.6446934477689037,0.05797274208288632,0.0,0.272142090833234,0.0]   |\n",
      "|6.0       |4.0       |[0.0,0.0,0.031862745098039214,0.29558823529411765,0.47794117647058826,0.0,0.1946078431372549,0.0]|\n",
      "|6.0       |3.0       |[0.0,0.0,0.02519171931497596,0.6446934477689037,0.05797274208288632,0.0,0.272142090833234,0.0]   |\n",
      "|6.0       |3.0       |[0.0,0.0,0.02519171931497596,0.6446934477689037,0.05797274208288632,0.0,0.272142090833234,0.0]   |\n",
      "|6.0       |3.0       |[0.0,0.0,0.02519171931497596,0.6446934477689037,0.05797274208288632,0.0,0.272142090833234,0.0]   |\n",
      "|6.0       |3.0       |[0.0,0.0,0.02519171931497596,0.6446934477689037,0.05797274208288632,0.0,0.272142090833234,0.0]   |\n",
      "|6.0       |3.0       |[0.0,0.0,0.02519171931497596,0.6446934477689037,0.05797274208288632,0.0,0.272142090833234,0.0]   |\n",
      "|6.0       |3.0       |[0.0,0.0,0.02519171931497596,0.6446934477689037,0.05797274208288632,0.0,0.272142090833234,0.0]   |\n",
      "|6.0       |3.0       |[0.0,0.0,0.02519171931497596,0.6446934477689037,0.05797274208288632,0.0,0.272142090833234,0.0]   |\n",
      "|6.0       |3.0       |[0.0,0.0,0.02519171931497596,0.6446934477689037,0.05797274208288632,0.0,0.272142090833234,0.0]   |\n",
      "+----------+----------+-------------------------------------------------------------------------------------------------+\n",
      "only showing top 10 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "predictions.select(\"Cover_Type\", \"prediction\", \"probability\").show(10, truncate=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "be7e8d7a-3dfb-4d1a-ba55-f1c3ee848252",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.ml.evaluation import MulticlassClassificationEvaluator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "437db7f0-fd65-4010-9dfe-23ed077afe1f",
   "metadata": {},
   "outputs": [],
   "source": [
    "evaluator = MulticlassClassificationEvaluator(labelCol=\"Cover_Type\", predictionCol=\"prediction\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "fe178b8f-8c5b-4c01-b71c-96c4f1c87142",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.6994731223526981"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "evaluator.setMetricName(\"accuracy\").evaluate(predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "83b8d486-9e9b-4b49-b237-e1cbcebd82b6",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.6828279043961684"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "evaluator.setMetricName(\"f1\").evaluate(predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "028c0fcf-5ee0-4e5b-af5a-3d4ef61cf2a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "confusion_matrix = predictions.groupBy(\"Cover_Type\").pivot(\"prediction\", range(1, 8)).count().na.fill(0.0).orderBy(\"Cover_Type\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "3d639a32-941b-4ab1-853d-a612cd762b7a",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 28:>                                                         (0 + 1) / 1]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------+------+------+-----+---+---+---+-----+\n",
      "|Cover_Type|     1|     2|    3|  4|  5|  6|    7|\n",
      "+----------+------+------+-----+---+---+---+-----+\n",
      "|       1.0|133661| 51479|  113|  0|  0|  0| 5131|\n",
      "|       2.0| 56893|192442| 4900| 65| 21|  0|  728|\n",
      "|       3.0|     0|  3371|28261|603|  0|  0|    0|\n",
      "|       4.0|     0|     0| 1497|975|  0|  0|    0|\n",
      "|       5.0|     0|  8251|  274|  0| 72|  0|    0|\n",
      "|       6.0|     0|  3395|11819|397|  0|  0|    0|\n",
      "|       7.0|  8073|    76|    0|  0|  0|  0|10205|\n",
      "+----------+------+------+-----+---+---+---+-----+\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "confusion_matrix.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "1960ffae-a9f7-4f75-8579-317046e0a143",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql import DataFrame\n",
    "\n",
    "def class_probabilities(data):\n",
    "    total = data.count()\n",
    "    return data.groupBy(\"Cover_Type\").count().\\\n",
    "    orderBy(\"Cover_Type\").\\\n",
    "    select(col(\"count\").cast(DoubleType())).\\\n",
    "    withColumn(\"count_proportion\", col(\"count\")/total).\\\n",
    "    select(\"count_proportion\").collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "9ab659a8-55b3-4b30-8833-5703bfd60b9c",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "train_prior_probabilities = class_probabilities(train_data)\n",
    "test_prior_probabilities = class_probabilities(test_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "0aee6a34-0520-4a4c-a92b-d3fe8c296cf5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Row(count_proportion=0.36423047931708696),\n",
       " Row(count_proportion=0.48794341709042627),\n",
       " Row(count_proportion=0.061669938129182596),\n",
       " Row(count_proportion=0.004729272128287246),\n",
       " Row(count_proportion=0.016447229970422916),\n",
       " Row(count_proportion=0.02986596569364571),\n",
       " Row(count_proportion=0.03511369767094827)]"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_prior_probabilities"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "f430abfe-3bec-470f-a698-5831e28f5e04",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Row(count_proportion=0.3679643285885783),\n",
       " Row(count_proportion=0.4845138055222089),\n",
       " Row(count_proportion=0.06034985422740525),\n",
       " Row(count_proportion=0.004716172183158978),\n",
       " Row(count_proportion=0.015366146458583434),\n",
       " Row(count_proportion=0.030114903104098784),\n",
       " Row(count_proportion=0.03697478991596639)]"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_prior_probabilities"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "c7e34671-d664-4948-a59f-ff534ebc1d26",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.37663368430746225"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_prior_probabilities = [p[0] for p in train_prior_probabilities]\n",
    "test_prior_probabilities = [p[0] for p in test_prior_probabilities]\n",
    "\n",
    "sum([train_p * cv_p for train_p, cv_p in zip(train_prior_probabilities, test_prior_probabilities)])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8f4afac1-e1ff-4fa3-b388-b78cf68b7f9b",
   "metadata": {},
   "source": [
    "## Tunning Decision trees"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "470e9e84-d7af-4abf-9cbf-0fefbd00de99",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.ml import Pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "dd0b794e-1765-4d7f-8d17-b076b4ead2b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "assembler = VectorAssembler(inputCols=input_cols, outputCol=\"featureVector\")\n",
    "classifer = DecisionTreeClassifier(seed=1234, labelCol=\"Cover_Type\", featuresCol=\"featureVector\",\n",
    "                                   predictionCol=\"prediction\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "9ee0bc19-1f9c-4add-8ce0-3766c82d4825",
   "metadata": {},
   "outputs": [],
   "source": [
    "pipeline = Pipeline(stages=[assembler, classifier])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "af744caf-c24c-46de-b722-50a8b69c0716",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.ml.tuning import ParamGridBuilder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "ca9765ae-250e-4bce-be74-7c5a50b027bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "paramGrid = ParamGridBuilder().addGrid(classifier.impurity, [\"gini\", \"entropy\"]). \\\n",
    "        addGrid(classifier.maxDepth, [1, 20]). \\\n",
    "        addGrid(classifier.maxBins, [40, 300]). \\\n",
    "        addGrid(classifier.minInfoGain, [0.0, 0.05]). \\\n",
    "        build()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "87f87ec3-386d-4dc3-81fd-bf3b5a9b8b40",
   "metadata": {},
   "outputs": [],
   "source": [
    "multiclassEval = MulticlassClassificationEvaluator(). \\\n",
    "    setLabelCol(\"Cover_Type\"). \\\n",
    "    setPredictionCol(\"prediction\"). \\\n",
    "    setMetricName(\"accuracy\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "56a5437a-58bc-4f7e-9707-0ff77eb5b4b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.ml.tuning import TrainValidationSplit\n",
    "\n",
    "validator = TrainValidationSplit(seed=1234, estimator=pipeline, evaluator=multiclassEval, estimatorParamMaps=paramGrid,trainRatio=0.9)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "4e265eea-7d59-4654-87fd-4941b258625e",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "23/12/30 20:13:20 WARN DAGScheduler: Broadcasting large task binary with size 1016.5 KiB\n",
      "23/12/30 20:13:21 WARN DAGScheduler: Broadcasting large task binary with size 1385.7 KiB\n",
      "23/12/30 20:13:23 WARN DAGScheduler: Broadcasting large task binary with size 1848.6 KiB\n",
      "23/12/30 20:13:25 WARN DAGScheduler: Broadcasting large task binary with size 2.4 MiB\n",
      "23/12/30 20:13:28 WARN DAGScheduler: Broadcasting large task binary with size 3.0 MiB\n",
      "23/12/30 20:13:29 WARN DAGScheduler: Broadcasting large task binary with size 3.7 MiB\n",
      "23/12/30 20:13:32 WARN DAGScheduler: Broadcasting large task binary with size 4.5 MiB\n",
      "23/12/30 20:13:35 WARN DAGScheduler: Broadcasting large task binary with size 5.3 MiB\n",
      "23/12/30 20:13:39 WARN DAGScheduler: Broadcasting large task binary with size 3.7 MiB\n",
      "23/12/30 20:14:15 WARN DAGScheduler: Broadcasting large task binary with size 1308.4 KiB\n",
      "23/12/30 20:14:19 WARN DAGScheduler: Broadcasting large task binary with size 1722.3 KiB\n",
      "23/12/30 20:14:25 WARN DAGScheduler: Broadcasting large task binary with size 2.2 MiB\n",
      "23/12/30 20:14:32 WARN DAGScheduler: Broadcasting large task binary with size 2.7 MiB\n",
      "23/12/30 20:14:39 WARN DAGScheduler: Broadcasting large task binary with size 3.3 MiB\n",
      "23/12/30 20:14:46 WARN DAGScheduler: Broadcasting large task binary with size 3.9 MiB\n",
      "23/12/30 20:14:53 WARN DAGScheduler: Broadcasting large task binary with size 4.5 MiB\n",
      "23/12/30 20:15:00 WARN DAGScheduler: Broadcasting large task binary with size 5.1 MiB\n",
      "23/12/30 20:15:01 WARN DAGScheduler: Broadcasting large task binary with size 5.2 MiB\n",
      "23/12/30 20:15:01 WARN DAGScheduler: Broadcasting large task binary with size 5.2 MiB\n",
      "23/12/30 20:15:03 WARN DAGScheduler: Broadcasting large task binary with size 3.2 MiB\n",
      "23/12/30 20:16:04 WARN DAGScheduler: Broadcasting large task binary with size 1086.3 KiB\n",
      "23/12/30 20:16:06 WARN DAGScheduler: Broadcasting large task binary with size 1515.6 KiB\n",
      "23/12/30 20:16:08 WARN DAGScheduler: Broadcasting large task binary with size 2.0 MiB\n",
      "23/12/30 20:16:11 WARN DAGScheduler: Broadcasting large task binary with size 2.6 MiB\n",
      "23/12/30 20:16:13 WARN DAGScheduler: Broadcasting large task binary with size 3.4 MiB\n",
      "23/12/30 20:16:15 WARN DAGScheduler: Broadcasting large task binary with size 4.2 MiB\n",
      "23/12/30 20:16:19 WARN DAGScheduler: Broadcasting large task binary with size 5.0 MiB\n",
      "23/12/30 20:16:22 WARN DAGScheduler: Broadcasting large task binary with size 5.9 MiB\n",
      "23/12/30 20:16:25 WARN DAGScheduler: Broadcasting large task binary with size 4.1 MiB\n",
      "23/12/30 20:16:39 WARN DAGScheduler: Broadcasting large task binary with size 1060.4 KiB\n",
      "23/12/30 20:16:40 WARN DAGScheduler: Broadcasting large task binary with size 1102.4 KiB\n",
      "23/12/30 20:17:03 WARN DAGScheduler: Broadcasting large task binary with size 1141.5 KiB\n",
      "23/12/30 20:17:08 WARN DAGScheduler: Broadcasting large task binary with size 1558.1 KiB\n",
      "23/12/30 20:17:14 WARN DAGScheduler: Broadcasting large task binary with size 2.0 MiB\n",
      "23/12/30 20:17:22 WARN DAGScheduler: Broadcasting large task binary with size 2.6 MiB\n",
      "23/12/30 20:17:34 WARN DAGScheduler: Broadcasting large task binary with size 3.2 MiB\n",
      "23/12/30 20:17:41 WARN DAGScheduler: Broadcasting large task binary with size 3.8 MiB\n",
      "23/12/30 20:17:47 WARN DAGScheduler: Broadcasting large task binary with size 4.4 MiB\n",
      "23/12/30 20:17:54 WARN DAGScheduler: Broadcasting large task binary with size 5.0 MiB\n",
      "23/12/30 20:17:59 WARN DAGScheduler: Broadcasting large task binary with size 5.6 MiB\n",
      "23/12/30 20:18:00 WARN DAGScheduler: Broadcasting large task binary with size 5.6 MiB\n",
      "23/12/30 20:18:01 WARN DAGScheduler: Broadcasting large task binary with size 5.7 MiB\n",
      "23/12/30 20:18:01 WARN DAGScheduler: Broadcasting large task binary with size 5.7 MiB\n",
      "23/12/30 20:18:03 WARN DAGScheduler: Broadcasting large task binary with size 3.5 MiB\n",
      "23/12/30 20:18:23 WARN DAGScheduler: Broadcasting large task binary with size 1022.2 KiB\n",
      "23/12/30 20:18:24 WARN DAGScheduler: Broadcasting large task binary with size 1067.9 KiB\n",
      "23/12/30 20:18:48 WARN DAGScheduler: Broadcasting large task binary with size 1101.8 KiB\n",
      "23/12/30 20:18:54 WARN DAGScheduler: Broadcasting large task binary with size 1508.6 KiB\n",
      "23/12/30 20:19:01 WARN DAGScheduler: Broadcasting large task binary with size 2016.8 KiB\n",
      "23/12/30 20:19:07 WARN DAGScheduler: Broadcasting large task binary with size 2.5 MiB\n",
      "23/12/30 20:19:13 WARN DAGScheduler: Broadcasting large task binary with size 3.2 MiB\n",
      "23/12/30 20:19:19 WARN DAGScheduler: Broadcasting large task binary with size 3.8 MiB\n",
      "23/12/30 20:19:26 WARN DAGScheduler: Broadcasting large task binary with size 4.4 MiB\n",
      "23/12/30 20:19:31 WARN DAGScheduler: Broadcasting large task binary with size 5.0 MiB\n",
      "23/12/30 20:19:38 WARN DAGScheduler: Broadcasting large task binary with size 5.6 MiB\n",
      "23/12/30 20:19:40 WARN DAGScheduler: Broadcasting large task binary with size 5.7 MiB\n",
      "23/12/30 20:19:42 WARN DAGScheduler: Broadcasting large task binary with size 5.8 MiB\n",
      "23/12/30 20:19:43 WARN DAGScheduler: Broadcasting large task binary with size 5.9 MiB\n",
      "23/12/30 20:19:45 WARN DAGScheduler: Broadcasting large task binary with size 6.0 MiB\n",
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "validator_model = validator.fit(train_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "15dd1d0c-1f85-404a-a75e-e999f4ff7a95",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{Param(parent='DecisionTreeClassifier_598c49fddac8', name='probabilityCol', doc='Column name for predicted class conditional probabilities. Note: Not all models output well-calibrated probability estimates! These probabilities should be treated as confidences, not precise probabilities.'): 'probability',\n",
      " Param(parent='DecisionTreeClassifier_598c49fddac8', name='minWeightFractionPerNode', doc='Minimum fraction of the weighted sample count that each child must have after split. If a split causes the fraction of the total weight in the left or right child to be less than minWeightFractionPerNode, the split will be discarded as invalid. Should be in interval [0.0, 0.5).'): 0.0,\n",
      " Param(parent='DecisionTreeClassifier_598c49fddac8', name='predictionCol', doc='prediction column name.'): 'prediction',\n",
      " Param(parent='DecisionTreeClassifier_598c49fddac8', name='rawPredictionCol', doc='raw prediction (a.k.a. confidence) column name.'): 'rawPrediction',\n",
      " Param(parent='DecisionTreeClassifier_598c49fddac8', name='minInstancesPerNode', doc='Minimum number of instances each child must have after split. If a split causes the left or right child to have fewer than minInstancesPerNode, the split will be discarded as invalid. Should be >= 1.'): 1,\n",
      " Param(parent='DecisionTreeClassifier_598c49fddac8', name='seed', doc='random seed.'): 1234,\n",
      " Param(parent='DecisionTreeClassifier_598c49fddac8', name='checkpointInterval', doc='set checkpoint interval (>= 1) or disable checkpoint (-1). E.g. 10 means that the cache will get checkpointed every 10 iterations. Note: this setting will be ignored if the checkpoint directory is not set in the SparkContext.'): 10,\n",
      " Param(parent='DecisionTreeClassifier_598c49fddac8', name='maxMemoryInMB', doc='Maximum memory in MB allocated to histogram aggregation. If too small, then 1 node will be split per iteration, and its aggregates may exceed this size.'): 256,\n",
      " Param(parent='DecisionTreeClassifier_598c49fddac8', name='maxDepth', doc='Maximum depth of the tree. (>= 0) E.g., depth 0 means 1 leaf node; depth 1 means 1 internal node + 2 leaf nodes. Must be in range [0, 30].'): 20,\n",
      " Param(parent='DecisionTreeClassifier_598c49fddac8', name='minInfoGain', doc='Minimum information gain for a split to be considered at a tree node.'): 0.0,\n",
      " Param(parent='DecisionTreeClassifier_598c49fddac8', name='cacheNodeIds', doc='If false, the algorithm will pass trees to executors to match instances with nodes. If true, the algorithm will cache node IDs for each instance. Caching can speed up training of deeper trees. Users can set how often should the cache be checkpointed or disable it by setting checkpointInterval.'): False,\n",
      " Param(parent='DecisionTreeClassifier_598c49fddac8', name='leafCol', doc='Leaf indices column name. Predicted leaf index of each instance in each tree by preorder.'): '',\n",
      " Param(parent='DecisionTreeClassifier_598c49fddac8', name='labelCol', doc='label column name.'): 'Cover_Type',\n",
      " Param(parent='DecisionTreeClassifier_598c49fddac8', name='featuresCol', doc='features column name.'): 'featureVector',\n",
      " Param(parent='DecisionTreeClassifier_598c49fddac8', name='impurity', doc='Criterion used for information gain calculation (case-insensitive). Supported options: entropy, gini'): 'entropy',\n",
      " Param(parent='DecisionTreeClassifier_598c49fddac8', name='maxBins', doc='Max number of bins for discretizing continuous features.  Must be >=2 and >= number of categories for any categorical feature.'): 300}\n"
     ]
    }
   ],
   "source": [
    "from pprint import pprint\n",
    "\n",
    "best_model = validator_model.bestModel\n",
    "pprint(best_model.stages[1].extractParamMap())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "511acf73-bdfc-4442-8b50-0e3ad23f9bff",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "23/12/30 20:21:43 WARN DAGScheduler: Broadcasting large task binary with size 1016.5 KiB\n",
      "23/12/30 20:21:43 WARN DAGScheduler: Broadcasting large task binary with size 1385.7 KiB\n",
      "23/12/30 20:21:44 WARN DAGScheduler: Broadcasting large task binary with size 1848.6 KiB\n",
      "23/12/30 20:21:44 WARN DAGScheduler: Broadcasting large task binary with size 2.4 MiB\n",
      "23/12/30 20:21:45 WARN DAGScheduler: Broadcasting large task binary with size 3.0 MiB\n",
      "23/12/30 20:21:46 WARN DAGScheduler: Broadcasting large task binary with size 3.7 MiB\n",
      "23/12/30 20:21:47 WARN DAGScheduler: Broadcasting large task binary with size 4.5 MiB\n",
      "23/12/30 20:21:48 WARN DAGScheduler: Broadcasting large task binary with size 5.3 MiB\n",
      "23/12/30 20:21:49 WARN DAGScheduler: Broadcasting large task binary with size 3.7 MiB\n",
      "23/12/30 20:22:04 WARN DAGScheduler: Broadcasting large task binary with size 1308.4 KiB\n",
      "23/12/30 20:22:09 WARN DAGScheduler: Broadcasting large task binary with size 1722.3 KiB\n",
      "23/12/30 20:22:14 WARN DAGScheduler: Broadcasting large task binary with size 2.2 MiB\n",
      "23/12/30 20:22:20 WARN DAGScheduler: Broadcasting large task binary with size 2.7 MiB\n",
      "23/12/30 20:22:26 WARN DAGScheduler: Broadcasting large task binary with size 3.3 MiB\n",
      "23/12/30 20:22:32 WARN DAGScheduler: Broadcasting large task binary with size 3.9 MiB\n",
      "23/12/30 20:22:38 WARN DAGScheduler: Broadcasting large task binary with size 4.5 MiB\n",
      "23/12/30 20:22:47 WARN DAGScheduler: Broadcasting large task binary with size 5.1 MiB\n",
      "23/12/30 20:22:48 WARN DAGScheduler: Broadcasting large task binary with size 5.2 MiB\n",
      "23/12/30 20:22:49 WARN DAGScheduler: Broadcasting large task binary with size 5.2 MiB\n",
      "23/12/30 20:22:51 WARN DAGScheduler: Broadcasting large task binary with size 3.2 MiB\n",
      "23/12/30 20:23:47 WARN DAGScheduler: Broadcasting large task binary with size 1086.3 KiB\n",
      "23/12/30 20:23:49 WARN DAGScheduler: Broadcasting large task binary with size 1515.6 KiB\n",
      "23/12/30 20:23:50 WARN DAGScheduler: Broadcasting large task binary with size 2.0 MiB\n",
      "23/12/30 20:23:51 WARN DAGScheduler: Broadcasting large task binary with size 2.6 MiB\n",
      "23/12/30 20:23:52 WARN DAGScheduler: Broadcasting large task binary with size 3.4 MiB\n",
      "23/12/30 20:23:53 WARN DAGScheduler: Broadcasting large task binary with size 4.2 MiB\n",
      "23/12/30 20:23:56 WARN DAGScheduler: Broadcasting large task binary with size 5.0 MiB\n",
      "23/12/30 20:23:59 WARN DAGScheduler: Broadcasting large task binary with size 5.9 MiB\n",
      "23/12/30 20:24:03 WARN DAGScheduler: Broadcasting large task binary with size 4.1 MiB\n",
      "23/12/30 20:24:20 WARN DAGScheduler: Broadcasting large task binary with size 1060.4 KiB\n",
      "23/12/30 20:24:20 WARN DAGScheduler: Broadcasting large task binary with size 1102.4 KiB\n",
      "23/12/30 20:24:31 WARN BlockManager: Asked to remove block broadcast_1158_piece0, which does not exist\n",
      "23/12/30 20:24:41 WARN DAGScheduler: Broadcasting large task binary with size 1141.5 KiB\n",
      "23/12/30 20:24:44 WARN DAGScheduler: Broadcasting large task binary with size 1558.1 KiB\n",
      "23/12/30 20:24:51 WARN DAGScheduler: Broadcasting large task binary with size 2.0 MiB\n",
      "23/12/30 20:24:58 WARN DAGScheduler: Broadcasting large task binary with size 2.6 MiB\n",
      "23/12/30 20:25:05 WARN DAGScheduler: Broadcasting large task binary with size 3.2 MiB\n",
      "23/12/30 20:25:12 WARN DAGScheduler: Broadcasting large task binary with size 3.8 MiB\n",
      "23/12/30 20:25:18 WARN DAGScheduler: Broadcasting large task binary with size 4.4 MiB\n",
      "23/12/30 20:25:23 WARN DAGScheduler: Broadcasting large task binary with size 5.0 MiB\n",
      "23/12/30 20:25:31 WARN DAGScheduler: Broadcasting large task binary with size 5.6 MiB\n",
      "23/12/30 20:25:32 WARN DAGScheduler: Broadcasting large task binary with size 5.6 MiB\n",
      "23/12/30 20:25:33 WARN DAGScheduler: Broadcasting large task binary with size 5.7 MiB\n",
      "23/12/30 20:25:33 WARN DAGScheduler: Broadcasting large task binary with size 5.7 MiB\n",
      "23/12/30 20:25:35 WARN DAGScheduler: Broadcasting large task binary with size 3.5 MiB\n",
      "23/12/30 20:25:59 WARN DAGScheduler: Broadcasting large task binary with size 1022.2 KiB\n",
      "23/12/30 20:26:00 WARN DAGScheduler: Broadcasting large task binary with size 1067.9 KiB\n",
      "23/12/30 20:26:11 WARN DAGScheduler: Broadcasting large task binary with size 1101.8 KiB\n",
      "23/12/30 20:26:14 WARN DAGScheduler: Broadcasting large task binary with size 1508.6 KiB\n",
      "23/12/30 20:26:20 WARN DAGScheduler: Broadcasting large task binary with size 2016.8 KiB\n",
      "23/12/30 20:26:26 WARN DAGScheduler: Broadcasting large task binary with size 2.5 MiB\n",
      "23/12/30 20:26:33 WARN DAGScheduler: Broadcasting large task binary with size 3.2 MiB\n",
      "23/12/30 20:26:38 WARN DAGScheduler: Broadcasting large task binary with size 3.8 MiB\n",
      "23/12/30 20:26:45 WARN DAGScheduler: Broadcasting large task binary with size 4.4 MiB\n",
      "23/12/30 20:26:50 WARN DAGScheduler: Broadcasting large task binary with size 5.0 MiB\n",
      "23/12/30 20:26:57 WARN DAGScheduler: Broadcasting large task binary with size 5.6 MiB\n",
      "23/12/30 20:27:00 WARN DAGScheduler: Broadcasting large task binary with size 5.7 MiB\n",
      "23/12/30 20:27:03 WARN DAGScheduler: Broadcasting large task binary with size 5.8 MiB\n",
      "23/12/30 20:27:05 WARN DAGScheduler: Broadcasting large task binary with size 5.9 MiB\n",
      "23/12/30 20:27:07 WARN DAGScheduler: Broadcasting large task binary with size 6.0 MiB\n",
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "validator_model = validator.fit(train_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "0a2050ba-eb0a-4a6f-81a7-fb47695be74c",
   "metadata": {},
   "outputs": [],
   "source": [
    "metrics = validator_model.validationMetrics\n",
    "params = validator_model.getEstimatorParamMaps()\n",
    "metrics_and_params = list(zip(metrics, params))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "069900b6-3a68-4d6e-b823-1235e7efa799",
   "metadata": {},
   "outputs": [],
   "source": [
    "metrics_and_params.sort(key=lambda x: x[0], reverse=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "51ed4de6-7ee5-42d4-ba8d-062b1b374dc5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(0.9122247474265197,\n",
       "  {Param(parent='DecisionTreeClassifier_598c49fddac8', name='impurity', doc='Criterion used for information gain calculation (case-insensitive). Supported options: entropy, gini'): 'entropy',\n",
       "   Param(parent='DecisionTreeClassifier_598c49fddac8', name='maxDepth', doc='Maximum depth of the tree. (>= 0) E.g., depth 0 means 1 leaf node; depth 1 means 1 internal node + 2 leaf nodes. Must be in range [0, 30].'): 20,\n",
       "   Param(parent='DecisionTreeClassifier_598c49fddac8', name='maxBins', doc='Max number of bins for discretizing continuous features.  Must be >=2 and >= number of categories for any categorical feature.'): 300,\n",
       "   Param(parent='DecisionTreeClassifier_598c49fddac8', name='minInfoGain', doc='Minimum information gain for a split to be considered at a tree node.'): 0.0}),\n",
       " (0.9095700998835011,\n",
       "  {Param(parent='DecisionTreeClassifier_598c49fddac8', name='impurity', doc='Criterion used for information gain calculation (case-insensitive). Supported options: entropy, gini'): 'entropy',\n",
       "   Param(parent='DecisionTreeClassifier_598c49fddac8', name='maxDepth', doc='Maximum depth of the tree. (>= 0) E.g., depth 0 means 1 leaf node; depth 1 means 1 internal node + 2 leaf nodes. Must be in range [0, 30].'): 20,\n",
       "   Param(parent='DecisionTreeClassifier_598c49fddac8', name='maxBins', doc='Max number of bins for discretizing continuous features.  Must be >=2 and >= number of categories for any categorical feature.'): 40,\n",
       "   Param(parent='DecisionTreeClassifier_598c49fddac8', name='minInfoGain', doc='Minimum information gain for a split to be considered at a tree node.'): 0.0}),\n",
       " (0.9030385210366494,\n",
       "  {Param(parent='DecisionTreeClassifier_598c49fddac8', name='impurity', doc='Criterion used for information gain calculation (case-insensitive). Supported options: entropy, gini'): 'gini',\n",
       "   Param(parent='DecisionTreeClassifier_598c49fddac8', name='maxDepth', doc='Maximum depth of the tree. (>= 0) E.g., depth 0 means 1 leaf node; depth 1 means 1 internal node + 2 leaf nodes. Must be in range [0, 30].'): 20,\n",
       "   Param(parent='DecisionTreeClassifier_598c49fddac8', name='maxBins', doc='Max number of bins for discretizing continuous features.  Must be >=2 and >= number of categories for any categorical feature.'): 40,\n",
       "   Param(parent='DecisionTreeClassifier_598c49fddac8', name='minInfoGain', doc='Minimum information gain for a split to be considered at a tree node.'): 0.0}),\n",
       " (0.902790244647734,\n",
       "  {Param(parent='DecisionTreeClassifier_598c49fddac8', name='impurity', doc='Criterion used for information gain calculation (case-insensitive). Supported options: entropy, gini'): 'gini',\n",
       "   Param(parent='DecisionTreeClassifier_598c49fddac8', name='maxDepth', doc='Maximum depth of the tree. (>= 0) E.g., depth 0 means 1 leaf node; depth 1 means 1 internal node + 2 leaf nodes. Must be in range [0, 30].'): 20,\n",
       "   Param(parent='DecisionTreeClassifier_598c49fddac8', name='maxBins', doc='Max number of bins for discretizing continuous features.  Must be >=2 and >= number of categories for any categorical feature.'): 300,\n",
       "   Param(parent='DecisionTreeClassifier_598c49fddac8', name='minInfoGain', doc='Minimum information gain for a split to be considered at a tree node.'): 0.0}),\n",
       " (0.7214720880044307,\n",
       "  {Param(parent='DecisionTreeClassifier_598c49fddac8', name='impurity', doc='Criterion used for information gain calculation (case-insensitive). Supported options: entropy, gini'): 'entropy',\n",
       "   Param(parent='DecisionTreeClassifier_598c49fddac8', name='maxDepth', doc='Maximum depth of the tree. (>= 0) E.g., depth 0 means 1 leaf node; depth 1 means 1 internal node + 2 leaf nodes. Must be in range [0, 30].'): 20,\n",
       "   Param(parent='DecisionTreeClassifier_598c49fddac8', name='maxBins', doc='Max number of bins for discretizing continuous features.  Must be >=2 and >= number of categories for any categorical feature.'): 300,\n",
       "   Param(parent='DecisionTreeClassifier_598c49fddac8', name='minInfoGain', doc='Minimum information gain for a split to be considered at a tree node.'): 0.05}),\n",
       " (0.7203070987949046,\n",
       "  {Param(parent='DecisionTreeClassifier_598c49fddac8', name='impurity', doc='Criterion used for information gain calculation (case-insensitive). Supported options: entropy, gini'): 'entropy',\n",
       "   Param(parent='DecisionTreeClassifier_598c49fddac8', name='maxDepth', doc='Maximum depth of the tree. (>= 0) E.g., depth 0 means 1 leaf node; depth 1 means 1 internal node + 2 leaf nodes. Must be in range [0, 30].'): 20,\n",
       "   Param(parent='DecisionTreeClassifier_598c49fddac8', name='maxBins', doc='Max number of bins for discretizing continuous features.  Must be >=2 and >= number of categories for any categorical feature.'): 40,\n",
       "   Param(parent='DecisionTreeClassifier_598c49fddac8', name='minInfoGain', doc='Minimum information gain for a split to be considered at a tree node.'): 0.05}),\n",
       " (0.6655908023146999,\n",
       "  {Param(parent='DecisionTreeClassifier_598c49fddac8', name='impurity', doc='Criterion used for information gain calculation (case-insensitive). Supported options: entropy, gini'): 'gini',\n",
       "   Param(parent='DecisionTreeClassifier_598c49fddac8', name='maxDepth', doc='Maximum depth of the tree. (>= 0) E.g., depth 0 means 1 leaf node; depth 1 means 1 internal node + 2 leaf nodes. Must be in range [0, 30].'): 20,\n",
       "   Param(parent='DecisionTreeClassifier_598c49fddac8', name='maxBins', doc='Max number of bins for discretizing continuous features.  Must be >=2 and >= number of categories for any categorical feature.'): 300,\n",
       "   Param(parent='DecisionTreeClassifier_598c49fddac8', name='minInfoGain', doc='Minimum information gain for a split to be considered at a tree node.'): 0.05}),\n",
       " (0.6643876167376482,\n",
       "  {Param(parent='DecisionTreeClassifier_598c49fddac8', name='impurity', doc='Criterion used for information gain calculation (case-insensitive). Supported options: entropy, gini'): 'gini',\n",
       "   Param(parent='DecisionTreeClassifier_598c49fddac8', name='maxDepth', doc='Maximum depth of the tree. (>= 0) E.g., depth 0 means 1 leaf node; depth 1 means 1 internal node + 2 leaf nodes. Must be in range [0, 30].'): 20,\n",
       "   Param(parent='DecisionTreeClassifier_598c49fddac8', name='maxBins', doc='Max number of bins for discretizing continuous features.  Must be >=2 and >= number of categories for any categorical feature.'): 40,\n",
       "   Param(parent='DecisionTreeClassifier_598c49fddac8', name='minInfoGain', doc='Minimum information gain for a split to be considered at a tree node.'): 0.05}),\n",
       " (0.6288649949389813,\n",
       "  {Param(parent='DecisionTreeClassifier_598c49fddac8', name='impurity', doc='Criterion used for information gain calculation (case-insensitive). Supported options: entropy, gini'): 'gini',\n",
       "   Param(parent='DecisionTreeClassifier_598c49fddac8', name='maxDepth', doc='Maximum depth of the tree. (>= 0) E.g., depth 0 means 1 leaf node; depth 1 means 1 internal node + 2 leaf nodes. Must be in range [0, 30].'): 1,\n",
       "   Param(parent='DecisionTreeClassifier_598c49fddac8', name='maxBins', doc='Max number of bins for discretizing continuous features.  Must be >=2 and >= number of categories for any categorical feature.'): 300,\n",
       "   Param(parent='DecisionTreeClassifier_598c49fddac8', name='minInfoGain', doc='Minimum information gain for a split to be considered at a tree node.'): 0.0}),\n",
       " (0.6288649949389813,\n",
       "  {Param(parent='DecisionTreeClassifier_598c49fddac8', name='impurity', doc='Criterion used for information gain calculation (case-insensitive). Supported options: entropy, gini'): 'gini',\n",
       "   Param(parent='DecisionTreeClassifier_598c49fddac8', name='maxDepth', doc='Maximum depth of the tree. (>= 0) E.g., depth 0 means 1 leaf node; depth 1 means 1 internal node + 2 leaf nodes. Must be in range [0, 30].'): 1,\n",
       "   Param(parent='DecisionTreeClassifier_598c49fddac8', name='maxBins', doc='Max number of bins for discretizing continuous features.  Must be >=2 and >= number of categories for any categorical feature.'): 300,\n",
       "   Param(parent='DecisionTreeClassifier_598c49fddac8', name='minInfoGain', doc='Minimum information gain for a split to be considered at a tree node.'): 0.05}),\n",
       " (0.6286740131013541,\n",
       "  {Param(parent='DecisionTreeClassifier_598c49fddac8', name='impurity', doc='Criterion used for information gain calculation (case-insensitive). Supported options: entropy, gini'): 'gini',\n",
       "   Param(parent='DecisionTreeClassifier_598c49fddac8', name='maxDepth', doc='Maximum depth of the tree. (>= 0) E.g., depth 0 means 1 leaf node; depth 1 means 1 internal node + 2 leaf nodes. Must be in range [0, 30].'): 1,\n",
       "   Param(parent='DecisionTreeClassifier_598c49fddac8', name='maxBins', doc='Max number of bins for discretizing continuous features.  Must be >=2 and >= number of categories for any categorical feature.'): 40,\n",
       "   Param(parent='DecisionTreeClassifier_598c49fddac8', name='minInfoGain', doc='Minimum information gain for a split to be considered at a tree node.'): 0.0}),\n",
       " (0.6286740131013541,\n",
       "  {Param(parent='DecisionTreeClassifier_598c49fddac8', name='impurity', doc='Criterion used for information gain calculation (case-insensitive). Supported options: entropy, gini'): 'gini',\n",
       "   Param(parent='DecisionTreeClassifier_598c49fddac8', name='maxDepth', doc='Maximum depth of the tree. (>= 0) E.g., depth 0 means 1 leaf node; depth 1 means 1 internal node + 2 leaf nodes. Must be in range [0, 30].'): 1,\n",
       "   Param(parent='DecisionTreeClassifier_598c49fddac8', name='maxBins', doc='Max number of bins for discretizing continuous features.  Must be >=2 and >= number of categories for any categorical feature.'): 40,\n",
       "   Param(parent='DecisionTreeClassifier_598c49fddac8', name='minInfoGain', doc='Minimum information gain for a split to be considered at a tree node.'): 0.05}),\n",
       " (0.48686999866312713,\n",
       "  {Param(parent='DecisionTreeClassifier_598c49fddac8', name='impurity', doc='Criterion used for information gain calculation (case-insensitive). Supported options: entropy, gini'): 'entropy',\n",
       "   Param(parent='DecisionTreeClassifier_598c49fddac8', name='maxDepth', doc='Maximum depth of the tree. (>= 0) E.g., depth 0 means 1 leaf node; depth 1 means 1 internal node + 2 leaf nodes. Must be in range [0, 30].'): 1,\n",
       "   Param(parent='DecisionTreeClassifier_598c49fddac8', name='maxBins', doc='Max number of bins for discretizing continuous features.  Must be >=2 and >= number of categories for any categorical feature.'): 40,\n",
       "   Param(parent='DecisionTreeClassifier_598c49fddac8', name='minInfoGain', doc='Minimum information gain for a split to be considered at a tree node.'): 0.0}),\n",
       " (0.48686999866312713,\n",
       "  {Param(parent='DecisionTreeClassifier_598c49fddac8', name='impurity', doc='Criterion used for information gain calculation (case-insensitive). Supported options: entropy, gini'): 'entropy',\n",
       "   Param(parent='DecisionTreeClassifier_598c49fddac8', name='maxDepth', doc='Maximum depth of the tree. (>= 0) E.g., depth 0 means 1 leaf node; depth 1 means 1 internal node + 2 leaf nodes. Must be in range [0, 30].'): 1,\n",
       "   Param(parent='DecisionTreeClassifier_598c49fddac8', name='maxBins', doc='Max number of bins for discretizing continuous features.  Must be >=2 and >= number of categories for any categorical feature.'): 40,\n",
       "   Param(parent='DecisionTreeClassifier_598c49fddac8', name='minInfoGain', doc='Minimum information gain for a split to be considered at a tree node.'): 0.05}),\n",
       " (0.48686999866312713,\n",
       "  {Param(parent='DecisionTreeClassifier_598c49fddac8', name='impurity', doc='Criterion used for information gain calculation (case-insensitive). Supported options: entropy, gini'): 'entropy',\n",
       "   Param(parent='DecisionTreeClassifier_598c49fddac8', name='maxDepth', doc='Maximum depth of the tree. (>= 0) E.g., depth 0 means 1 leaf node; depth 1 means 1 internal node + 2 leaf nodes. Must be in range [0, 30].'): 1,\n",
       "   Param(parent='DecisionTreeClassifier_598c49fddac8', name='maxBins', doc='Max number of bins for discretizing continuous features.  Must be >=2 and >= number of categories for any categorical feature.'): 300,\n",
       "   Param(parent='DecisionTreeClassifier_598c49fddac8', name='minInfoGain', doc='Minimum information gain for a split to be considered at a tree node.'): 0.0}),\n",
       " (0.48686999866312713,\n",
       "  {Param(parent='DecisionTreeClassifier_598c49fddac8', name='impurity', doc='Criterion used for information gain calculation (case-insensitive). Supported options: entropy, gini'): 'entropy',\n",
       "   Param(parent='DecisionTreeClassifier_598c49fddac8', name='maxDepth', doc='Maximum depth of the tree. (>= 0) E.g., depth 0 means 1 leaf node; depth 1 means 1 internal node + 2 leaf nodes. Must be in range [0, 30].'): 1,\n",
       "   Param(parent='DecisionTreeClassifier_598c49fddac8', name='maxBins', doc='Max number of bins for discretizing continuous features.  Must be >=2 and >= number of categories for any categorical feature.'): 300,\n",
       "   Param(parent='DecisionTreeClassifier_598c49fddac8', name='minInfoGain', doc='Minimum information gain for a split to be considered at a tree node.'): 0.05})]"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "metrics_and_params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "1c72e78c-7337-4053-b4c8-29ba58eea39c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9122247474265197\n"
     ]
    }
   ],
   "source": [
    "metrics.sort(reverse=True)\n",
    "print(metrics[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "9cc11806-b583-4497-8cf4-e0038fa9517e",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "23/12/30 20:27:52 WARN DAGScheduler: Broadcasting large task binary with size 3.7 MiB\n",
      "                                                                                \r"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.9183844966558051"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "multiclassEval.evaluate(best_model.transform(test_data))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "id": "ea820603-eb0d-4724-b467-54724e791813",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql.functions import udf\n",
    "from pyspark.sql.types import IntegerType\n",
    "\n",
    "def unencode_one_hot(data):\n",
    "    wilderness_cols = ['Wilderness_Area_' + str(i) for i in range(4)]\n",
    "    wilderness_assembler = VectorAssembler().\\\n",
    "                            setInputCols(wilderness_cols).\\\n",
    "                            setOutputCol(\"wilderness\")\n",
    "\n",
    "    unhot_udf = udf(lambda v: v.toArray().tolist().index(1))\n",
    "\n",
    "    with_wilderness = wilderness_assembler.transform(data).\\\n",
    "      drop(*wilderness_cols).\\\n",
    "      withColumn(\"wilderness\", unhot_udf(col(\"wilderness\")).cast(IntegerType()))\n",
    "    \n",
    "    soil_cols = ['Soild_Type_' + str(i) for i in range(40)]\n",
    "    #print(soil_cols)\n",
    "    soil_assembler = VectorAssembler().\\\n",
    "                      setInputCols(soil_cols).\\\n",
    "                      setOutputCol(\"soil\")\n",
    "    #print(soil_assembler)\n",
    "    with_soil = soil_assembler.\\\n",
    "                transform(with_wilderness).\\\n",
    "                drop(*soil_cols).\\\n",
    "                withColumn(\"soil\", unhot_udf(col(\"soil\")).cast(IntegerType()))\n",
    "\n",
    "    return with_soil"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "id": "e4197e2c-f9d1-48ee-a5dd-f98a3209fd51",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Soild_Type_0', 'Soild_Type_1', 'Soild_Type_2', 'Soild_Type_3', 'Soild_Type_4', 'Soild_Type_5', 'Soild_Type_6', 'Soild_Type_7', 'Soild_Type_8', 'Soild_Type_9', 'Soild_Type_10', 'Soild_Type_11', 'Soild_Type_12', 'Soild_Type_13', 'Soild_Type_14', 'Soild_Type_15', 'Soild_Type_16', 'Soild_Type_17', 'Soild_Type_18', 'Soild_Type_19', 'Soild_Type_20', 'Soild_Type_21', 'Soild_Type_22', 'Soild_Type_23', 'Soild_Type_24', 'Soild_Type_25', 'Soild_Type_26', 'Soild_Type_27', 'Soild_Type_28', 'Soild_Type_29', 'Soild_Type_30', 'Soild_Type_31', 'Soild_Type_32', 'Soild_Type_33', 'Soild_Type_34', 'Soild_Type_35', 'Soild_Type_36', 'Soild_Type_37', 'Soild_Type_38', 'Soild_Type_39']\n",
      "root\n",
      " |-- Elevation: integer (nullable = true)\n",
      " |-- Aspect: integer (nullable = true)\n",
      " |-- Slope: integer (nullable = true)\n",
      " |-- Horizontal_Distance_To_Hydrology: integer (nullable = true)\n",
      " |-- Vertical_Distance_To_Hydrology: integer (nullable = true)\n",
      " |-- Horizontal_Distance_To_Roadways: integer (nullable = true)\n",
      " |-- Hillshade_9am: integer (nullable = true)\n",
      " |-- Hillshade_Noon: integer (nullable = true)\n",
      " |-- Hillshade_3pm: integer (nullable = true)\n",
      " |-- Horizontal_Distance_To_Fire_Points: integer (nullable = true)\n",
      " |-- Cover_Type: double (nullable = true)\n",
      " |-- wilderness: integer (nullable = true)\n",
      " |-- soil: integer (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "unenc_train_data = unencode_one_hot(train_data)\n",
    "unenc_train_data.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "id": "36f87b84-6e32-4728-a915-a898b6bee020",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 1047:>                                                       (0 + 8) / 8]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------+------+\n",
      "|wilderness| count|\n",
      "+----------+------+\n",
      "|         1| 26859|\n",
      "|         3| 33318|\n",
      "|         2|227991|\n",
      "|         0|234534|\n",
      "+----------+------+\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "unenc_train_data.groupBy('wilderness').count().show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "id": "6f411027-8615-4998-a802-0a6ca2997d63",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.ml.feature import VectorIndexer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "id": "68728a1b-7c36-49c3-a35b-5d366ec34b4c",
   "metadata": {},
   "outputs": [],
   "source": [
    "cols = unenc_train_data.columns\n",
    "inputCols = [c for c in cols if c != 'Cover_Type']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "id": "a791ab35-e3ea-4106-8d95-637a6a1e7b1f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Elevation',\n",
       " 'Aspect',\n",
       " 'Slope',\n",
       " 'Horizontal_Distance_To_Hydrology',\n",
       " 'Vertical_Distance_To_Hydrology',\n",
       " 'Horizontal_Distance_To_Roadways',\n",
       " 'Hillshade_9am',\n",
       " 'Hillshade_Noon',\n",
       " 'Hillshade_3pm',\n",
       " 'Horizontal_Distance_To_Fire_Points',\n",
       " 'wilderness',\n",
       " 'soil']"
      ]
     },
     "execution_count": 110,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "inputCols"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "id": "45073b49-9183-40de-b2bb-00835c2a1bcf",
   "metadata": {},
   "outputs": [],
   "source": [
    "assembler = VectorAssembler().setInputCols(inputCols).setOutputCol(\"featureVector\")\n",
    "\n",
    "indexer = VectorIndexer().setMaxCategories(40).setInputCol(\"featureVector\").setOutputCol(\"indexedVector\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "id": "58fe72b8-262a-42d7-9c56-9c7d2d38656a",
   "metadata": {},
   "outputs": [],
   "source": [
    "classifier = DecisionTreeClassifier().setLabelCol(\"Cover_Type\").\\\n",
    "            setFeaturesCol(\"indexedVector\").setPredictionCol(\"prediction\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "id": "7acc2fbf-ea5c-4a65-81a0-325965c61141",
   "metadata": {},
   "outputs": [],
   "source": [
    "pipeline = Pipeline().setStages([assembler, indexer, classifier])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e62972cf-9e4f-429d-95ff-f9b32d8fa613",
   "metadata": {},
   "source": [
    "## Random Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "id": "d8b0840d-8268-4748-839a-668d5d6abb8b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.ml.classification import RandomForestClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "id": "2178480d-22d4-47c2-b622-3d9f5f7bd9ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "classifier = RandomForestClassifier(seed=1234, labelCol=\"Cover_Type\", featuresCol=\"indexedVector\",\n",
    "                                    predictionCol=\"prediction\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "id": "f1f0701f-e0b2-4075-b4ba-3fe3c0a244da",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DecisionTreeClassificationModel: uid=DecisionTreeClassifier_598c49fddac8, depth=20, numNodes=30035, numClasses=8, numFeatures=54\n"
     ]
    }
   ],
   "source": [
    "forest_model = best_model.stages[1]\n",
    "print(forest_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "id": "088b74a3-78b7-4a97-8665-be03e4f3355c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('Elevation', 0.4486348679871917),\n",
      " ('Horizontal_Distance_To_Roadways', 0.11893637319958811),\n",
      " ('Horizontal_Distance_To_Fire_Points', 0.11643411690977616),\n",
      " ('Horizontal_Distance_To_Hydrology', 0.051322319061203),\n",
      " ('Vertical_Distance_To_Hydrology', 0.04044003435468446),\n",
      " ('Wilderness_Area_0', 0.027693664230934643),\n",
      " ('Aspect', 0.027502211672359722),\n",
      " ('Hillshade_Noon', 0.02310068225756841),\n",
      " ('Hillshade_9am', 0.021285627577415454),\n",
      " ('Slope', 0.013330385497054417),\n",
      " ('Hillshade_3pm', 0.01286820563505776),\n",
      " ('Soild_Type_3', 0.00918791600138428),\n",
      " ('Wilderness_Area_2', 0.007768885467239391),\n",
      " ('Soild_Type_31', 0.007549332855271837),\n",
      " ('Soild_Type_22', 0.006258055983231977),\n",
      " ('Soild_Type_21', 0.006164893584875155),\n",
      " ('Soild_Type_28', 0.006142013020123907),\n",
      " ('Soild_Type_1', 0.005885529900451296),\n",
      " ('Soild_Type_38', 0.005514212255874858),\n",
      " ('Soild_Type_30', 0.004575327832903735),\n",
      " ('Wilderness_Area_1', 0.00444800514857005),\n",
      " ('Soild_Type_23', 0.003889479278551446),\n",
      " ('Soild_Type_9', 0.003788947735224453),\n",
      " ('Soild_Type_32', 0.0034354483711258633),\n",
      " ('Soild_Type_37', 0.0031777002859088707),\n",
      " ('Soild_Type_2', 0.002875891495662924),\n",
      " ('Soild_Type_29', 0.0028057211416586134),\n",
      " ('Soild_Type_10', 0.0023782194051913826),\n",
      " ('Soild_Type_12', 0.0022766441360828017),\n",
      " ('Soild_Type_16', 0.0017426397997745875),\n",
      " ('Soild_Type_19', 0.0014171275327690234),\n",
      " ('Soild_Type_34', 0.0012383230082564395),\n",
      " ('Wilderness_Area_3', 0.000691930935262906),\n",
      " ('Soild_Type_15', 0.0005579410639980122),\n",
      " ('Soild_Type_11', 0.0005399199852291038),\n",
      " ('Soild_Type_5', 0.0005267992660332088),\n",
      " ('Soild_Type_33', 0.0005084531370533492),\n",
      " ('Soild_Type_18', 0.0005032281545452014),\n",
      " ('Soild_Type_39', 0.0005030130016839821),\n",
      " ('Soild_Type_8', 0.00039896394145099313),\n",
      " ('Soild_Type_20', 0.0003015106090077044),\n",
      " ('Soild_Type_17', 0.0002985172704678096),\n",
      " ('Soild_Type_26', 0.00023989993652215468),\n",
      " ('Soild_Type_13', 0.00022015732958875707),\n",
      " ('Soild_Type_0', 0.0001842013579120256),\n",
      " ('Soild_Type_4', 0.00015960798831429879),\n",
      " ('Soild_Type_25', 0.00010201707791842212),\n",
      " ('Soild_Type_27', 6.641549467685321e-05),\n",
      " ('Soild_Type_7', 5.291762408889165e-05),\n",
      " ('Soild_Type_24', 4.376621430811906e-05),\n",
      " ('Soild_Type_35', 3.193698897162155e-05),\n",
      " ('Soild_Type_6', 0.0),\n",
      " ('Soild_Type_14', 0.0),\n",
      " ('Soild_Type_36', 0.0)]\n"
     ]
    }
   ],
   "source": [
    "feature_importance_list = list(zip(input_cols, forest_model.featureImportances.toArray()))\n",
    "feature_importance_list.sort(key=lambda x: x[1], reverse=True)\n",
    "pprint(feature_importance_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "id": "236a316c-de88-413e-93e7-678d5151e2a8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Soild_Type_0', 'Soild_Type_1', 'Soild_Type_2', 'Soild_Type_3', 'Soild_Type_4', 'Soild_Type_5', 'Soild_Type_6', 'Soild_Type_7', 'Soild_Type_8', 'Soild_Type_9', 'Soild_Type_10', 'Soild_Type_11', 'Soild_Type_12', 'Soild_Type_13', 'Soild_Type_14', 'Soild_Type_15', 'Soild_Type_16', 'Soild_Type_17', 'Soild_Type_18', 'Soild_Type_19', 'Soild_Type_20', 'Soild_Type_21', 'Soild_Type_22', 'Soild_Type_23', 'Soild_Type_24', 'Soild_Type_25', 'Soild_Type_26', 'Soild_Type_27', 'Soild_Type_28', 'Soild_Type_29', 'Soild_Type_30', 'Soild_Type_31', 'Soild_Type_32', 'Soild_Type_33', 'Soild_Type_34', 'Soild_Type_35', 'Soild_Type_36', 'Soild_Type_37', 'Soild_Type_38', 'Soild_Type_39']\n"
     ]
    }
   ],
   "source": [
    "unenc_test_data = unencode_one_hot(test_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "id": "111c1088-80c6-45eb-b4a4-8fdfa7bb7650",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DataFrame[Elevation: int, Aspect: int, Slope: int, Horizontal_Distance_To_Hydrology: int, Vertical_Distance_To_Hydrology: int, Horizontal_Distance_To_Roadways: int, Hillshade_9am: int, Hillshade_Noon: int, Hillshade_3pm: int, Horizontal_Distance_To_Fire_Points: int, Cover_Type: double, wilderness: int, soil: int]"
      ]
     },
     "execution_count": 123,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "unenc_test_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "id": "b2ae1428-b24a-4c5b-9b01-f937fff19e3a",
   "metadata": {},
   "outputs": [],
   "source": [
    "tmp = test_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "id": "fbfdd2e8-f644-46dd-b37e-c51816e211db",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DataFrame[Elevation: int, Aspect: int, Slope: int, Horizontal_Distance_To_Hydrology: int, Vertical_Distance_To_Hydrology: int, Horizontal_Distance_To_Roadways: int, Hillshade_9am: int, Hillshade_Noon: int, Hillshade_3pm: int, Horizontal_Distance_To_Fire_Points: int, Wilderness_Area_0: int, Wilderness_Area_1: int, Wilderness_Area_2: int, Wilderness_Area_3: int, Soild_Type_0: int, Soild_Type_1: int, Soild_Type_2: int, Soild_Type_3: int, Soild_Type_4: int, Soild_Type_5: int, Soild_Type_6: int, Soild_Type_7: int, Soild_Type_8: int, Soild_Type_9: int, Soild_Type_10: int, Soild_Type_11: int, Soild_Type_12: int, Soild_Type_13: int, Soild_Type_14: int, Soild_Type_15: int, Soild_Type_16: int, Soild_Type_17: int, Soild_Type_18: int, Soild_Type_19: int, Soild_Type_20: int, Soild_Type_21: int, Soild_Type_22: int, Soild_Type_23: int, Soild_Type_24: int, Soild_Type_25: int, Soild_Type_26: int, Soild_Type_27: int, Soild_Type_28: int, Soild_Type_29: int, Soild_Type_30: int, Soild_Type_31: int, Soild_Type_32: int, Soild_Type_33: int, Soild_Type_34: int, Soild_Type_35: int, Soild_Type_36: int, Soild_Type_37: int, Soild_Type_38: int, Soild_Type_39: int]"
      ]
     },
     "execution_count": 132,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tmp.drop(\"Cover_Type\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "id": "f8e6480c-e086-4b5d-a7ff-a883acdc3c13",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------+\n",
      "|prediction|\n",
      "+----------+\n",
      "|       6.0|\n",
      "+----------+\n",
      "only showing top 1 row\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "23/12/30 21:18:44 WARN DAGScheduler: Broadcasting large task binary with size 3.7 MiB\n"
     ]
    }
   ],
   "source": [
    "best_model.transform(tmp).select(\"prediction\").show(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6a3549d2-eb59-4b46-beb7-40c2d848e4d4",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
