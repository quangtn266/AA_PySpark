{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "365b8a93-a57d-4ac4-80bc-aab0bdfe2657",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pyspark\n",
    "from pyspark.sql import SparkSession"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "7558725f-a5f0-49f6-8310-da6763914b3b",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "24/01/05 15:33:09 WARN Utils: Your hostname, quangtn933.local resolves to a loopback address: 127.0.0.1; using 192.168.1.90 instead (on interface en0)\n",
      "24/01/05 15:33:09 WARN Utils: Set SPARK_LOCAL_IP if you need to bind to another address\n",
      "Setting default log level to \"WARN\".\n",
      "To adjust logging level use sc.setLogLevel(newLevel). For SparkR, use setLogLevel(newLevel).\n",
      "24/01/05 15:33:10 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable\n"
     ]
    }
   ],
   "source": [
    "spark = SparkSession.builder.config(\"spark.driver.memory\", \"8g\").appName(\"chapter11\").getOrCreate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "89694f29-81fb-4215-9475-4821d65a3724",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.ml import Pipeline\n",
    "from pyspark.sql.functions import col\n",
    "from pyspark.sql.types import DoubleType\n",
    "from pyspark.ml.feature import VectorAssembler\n",
    "from pyspark.ml.classification import DecisionTreeClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "44e97841-4c0e-4455-af66-2b25da3cb8b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_without_header = spark.read.option(\"inSchema\", True).option(\"header\", False).\\\n",
    "    csv(\"/Users/quangtn/Desktop/01_work/01_job/02_ml/PySpark/covtype.data\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "f9bb8f00-1831-4420-ad8c-ace148930e3a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DataFrame[_c0: string, _c1: string, _c2: string, _c3: string, _c4: string, _c5: string, _c6: string, _c7: string, _c8: string, _c9: string, _c10: string, _c11: string, _c12: string, _c13: string, _c14: string, _c15: string, _c16: string, _c17: string, _c18: string, _c19: string, _c20: string, _c21: string, _c22: string, _c23: string, _c24: string, _c25: string, _c26: string, _c27: string, _c28: string, _c29: string, _c30: string, _c31: string, _c32: string, _c33: string, _c34: string, _c35: string, _c36: string, _c37: string, _c38: string, _c39: string, _c40: string, _c41: string, _c42: string, _c43: string, _c44: string, _c45: string, _c46: string, _c47: string, _c48: string, _c49: string, _c50: string, _c51: string, _c52: string, _c53: string, _c54: string]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_without_header"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "33d8b49e-e184-4d08-ac8f-c2618666b138",
   "metadata": {},
   "outputs": [],
   "source": [
    "colnames = [\"Elevation\", \"Aspect\", \"Slope\", \"Horizontal_Distance_To_Hydrology\",\n",
    "            \"Vertical_Distance_To_Hydrology\", \"Horizontal_Distance_To_Roadways\",\n",
    "            \"Hillshade_9am\", \"Hillshade_Noon\", \"Hillshade_3pm\", \"Horizontal_Distance_To_Fire_Points\"] + \\\n",
    "[f\"Wilderness_Area_{i}\" for i in range(4)]+ [f\"Solid_Type_{i}\" for i in range(40)] + [\"Cover_Type\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "bd407deb-f530-4d36-8853-b3478b8ca1a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = data_without_header.toDF(*colnames).withColumn(\"Cover_Type\", col(\"Cover_Type\").cast(DoubleType()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "dcdf3c1d-f78c-46fc-b853-ca9290aa9181",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql.functions import col\n",
    "\n",
    "#table = spark.sql(\"table\")\n",
    "\n",
    "data = data.select([col(c).cast(\"double\") for c in data.columns])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "517f8c47-0dc7-459e-96df-d4d2fb215133",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DataFrame[Elevation: double, Aspect: double, Slope: double, Horizontal_Distance_To_Hydrology: double, Vertical_Distance_To_Hydrology: double, Horizontal_Distance_To_Roadways: double, Hillshade_9am: double, Hillshade_Noon: double, Hillshade_3pm: double, Horizontal_Distance_To_Fire_Points: double, Wilderness_Area_0: double, Wilderness_Area_1: double, Wilderness_Area_2: double, Wilderness_Area_3: double, Solid_Type_0: double, Solid_Type_1: double, Solid_Type_2: double, Solid_Type_3: double, Solid_Type_4: double, Solid_Type_5: double, Solid_Type_6: double, Solid_Type_7: double, Solid_Type_8: double, Solid_Type_9: double, Solid_Type_10: double, Solid_Type_11: double, Solid_Type_12: double, Solid_Type_13: double, Solid_Type_14: double, Solid_Type_15: double, Solid_Type_16: double, Solid_Type_17: double, Solid_Type_18: double, Solid_Type_19: double, Solid_Type_20: double, Solid_Type_21: double, Solid_Type_22: double, Solid_Type_23: double, Solid_Type_24: double, Solid_Type_25: double, Solid_Type_26: double, Solid_Type_27: double, Solid_Type_28: double, Solid_Type_29: double, Solid_Type_30: double, Solid_Type_31: double, Solid_Type_32: double, Solid_Type_33: double, Solid_Type_34: double, Solid_Type_35: double, Solid_Type_36: double, Solid_Type_37: double, Solid_Type_38: double, Solid_Type_39: double, Cover_Type: double]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "811434e0-12db-4963-a8ad-2a4d9529f90d",
   "metadata": {},
   "outputs": [],
   "source": [
    "(train_data, test_data) = data.randomSplit([0.9, 0.1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "71d532f3-c291-4c40-ac0f-e1f3a99d4272",
   "metadata": {},
   "outputs": [],
   "source": [
    "input_cols = colnames[:-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "35f7f6d4-5f31-408c-8f30-09ea62973d27",
   "metadata": {},
   "outputs": [],
   "source": [
    "vector_assembler = VectorAssembler(inputCols=input_cols, outputCol=\"featureVector\")\n",
    "classifier = DecisionTreeClassifier(seed=1234, labelCol=\"Cover_Type\",\\\n",
    "                                    featuresCol=\"featureVector\",predictionCol=\"prediction\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "c72fba61-bb05-4261-8ec1-a40cf890bc19",
   "metadata": {},
   "outputs": [],
   "source": [
    "pipeline = Pipeline(stages=[vector_assembler, classifier])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "6e7d46f0-ef59-47fe-a28e-d8f220046eb0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import mlflow\n",
    "import mlflow.spark\n",
    "import pandas as pd\n",
    "from pyspark.ml.evaluation import MulticlassClassificationEvaluator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "903c89ff-12fb-462b-816f-df9d94b404bb",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "24/01/05 15:33:23 WARN SparkStringUtils: Truncated the string representation of a plan since it was too large. This behavior can be adjusted by setting 'spark.sql.debug.maxToStringFields'.\n",
      "24/01/05 15:33:28 WARN GarbageCollectionMetrics: To enable non-built-in garbage collector(s) List(G1 Concurrent GC), users should configure it(them) to spark.eventLog.gcMetrics.youngGenerationGarbageCollectors or spark.eventLog.gcMetrics.oldGenerationGarbageCollectors\n",
      "/Users/quangtn/opt/anaconda3/envs/bentoML/lib/python3.8/site-packages/_distutils_hack/__init__.py:33: UserWarning: Setuptools is replacing distutils.\n",
      "  warnings.warn(\"Setuptools is replacing distutils.\")\n",
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "with mlflow.start_run(run_name=\"decision-tree\"):\n",
    "    # log param: max_depth\n",
    "    mlflow.log_param(\"max_depth\", classifier.getMaxDepth())\n",
    "    # Log model\n",
    "    pipeline_model = pipeline.fit(train_data)\n",
    "    mlflow.spark.log_model(pipeline_model, \"model\")\n",
    "    # Log metrics: Accuracy and F1\n",
    "    pred_df = pipeline_model.transform(test_data)\n",
    "    evaluator = MulticlassClassificationEvaluator(labelCol=\"Cover_Type\", predictionCol=\"prediction\")\n",
    "    accuracy = evaluator.setMetricName(\"accuracy\").evaluate(pred_df)\n",
    "    f1 = evaluator.setMetricName(\"f1\").evaluate(pred_df)\n",
    "    mlflow.log_metrics({\"accuracy\": accuracy, \"f1\": f1})\n",
    "    # Log artifact: feature importance scores.\n",
    "    tree_model = pipeline_model.stages[-1]\n",
    "    feature_importance_df = (pd.DataFrame(list(zip(vector_assembler.getInputCols(), \\\n",
    "        tree_model.featureImportances)), columns=[\"feature\", \"importance\"]).sort_values(by=\"importance\", \\\n",
    "        ascending=False))\n",
    "    feature_importance_df.to_csv(\"feature-importance.csv\", index=False)\n",
    "    mlflow.log_artifact(\"feature-importance.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "242f892d-e35d-4952-ab34-ab488397939e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/Users/quangtn/opt/anaconda3/envs/bentoML/lib/python3.8/site-packages/pydantic/_internal/_config.py:321: UserWarning: Valid config keys have changed in V2:\n",
      "* 'schema_extra' has been renamed to 'json_schema_extra'\n",
      "  warnings.warn(message, UserWarning)\n",
      "/Users/quangtn/opt/anaconda3/envs/bentoML/bin/python: No module named gunicorn.__main__; 'gunicorn' is a package and cannot be directly executed\n",
      "Running the mlflow server failed. Please see the logs above for details.\n"
     ]
    }
   ],
   "source": [
    "!mlflow ui"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eb201809-1f74-48b9-9779-6b6b94807dde",
   "metadata": {},
   "source": [
    "## Calling model through API by MLflow."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9093d3ce-40c3-46c4-877c-e18834bdfe82",
   "metadata": {},
   "source": [
    "$ mlflow models serve --model-uri runs:/0433bb047f514e28a73109bbab767222/model -p 7000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "12b37aa5-cfbe-486c-8853-c057393656c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "a82c3ef9-2707-43af-a7bc-da6b31c391a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "host= \"0.0.0.0\"\n",
    "port = \"7001\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "597ba9ed-a108-4c91-9205-71eab8f18b92",
   "metadata": {},
   "outputs": [],
   "source": [
    "url = f'http://{host}:{port}/invocations'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "8a337c34-dc2c-4193-9817-9f665a2d5e4f",
   "metadata": {},
   "outputs": [],
   "source": [
    "headers = {\n",
    "    'Content-Type': 'application/json;',\n",
    "    'format': 'pandas-split'\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "4ab52d73-a1ab-4372-872c-2f843c7a8f12",
   "metadata": {},
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "EOL while scanning string literal (1816678397.py, line 2)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;36m  Cell \u001b[0;32mIn[33], line 2\u001b[0;36m\u001b[0m\n\u001b[0;31m    \"Horizontal_Distance_To_Hydrology\",\\\u001b[0m\n\u001b[0m                                         \n^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m EOL while scanning string literal\n"
     ]
    }
   ],
   "source": [
    "http_data = '{\"columns\": [\"Elevation\", \"Aspect\", \"Slope\",\\\n",
    "    \"Horizontal_Distance_To_Hydrology\",\\ \n",
    "    \"Vertical_Distance_To_Hydrology\",\"Horizontal_Distance_To_Roadways\", \\ \n",
    "    \"Hillshade_9am\",\"Hillshade_Noon\",\"Hillshade_3pm\",\\ \n",
    "    \"Horizontal_Distance_To_Fire_Points\",\\ \n",
    "    \"Wilderness_Area_0\",\"Wilderness_Area_1\",\"Wilderness_Area_2\",\\ \n",
    "    \"Wilderness_Area_3\",\"Soil_Type_0\",\"Soil_Type_1\",\"Soil_Type_2\",\\ \n",
    "    \"Soil_Type_3\",\"Soil_Type_4\",\"Soil_Type_5\",\"Soil_Type_6\",\\ \n",
    "    \"Soil_Type_7\",\"Soil_Type_8\",\"Soil_Type_9\",\"Soil_Type_10\",\\ \n",
    "    \"Soil_Type_11\",\"Soil_Type_12\",\"Soil_Type_13\", \\ \n",
    "    \"Soil_Type_14\",\"Soil_Type_15\",\"Soil_Type_16\", \\ \n",
    "    \"Soil_Type_17\",\"Soil_Type_18\",\"Soil_Type_19\", \\\n",
    "    \"Soil_Type_20\",\"Soil_Type_21\",\"Soil_Type_22\", \\ \n",
    "    \"Soil_Type_23\",\"Soil_Type_24\",\"Soil_Type_25\", \\ \n",
    "    \"Soil_Type_26\",\"Soil_Type_27\",\"Soil_Type_28\", \\ \n",
    "    \"Soil_Type_29\",\"Soil_Type_30\",\"Soil_Type_31\", \\ \n",
    "    \"Soil_Type_32\",\"Soil_Type_33\",\"Soil_Type_34\", \\ \n",
    "    \"Soil_Type_35\",\"Soil_Type_36\",\"Soil_Type_37\", \\ \n",
    "    \"Soil_Type_38\",\"Soil_Type_39\",\"Cover_Type\"], \\ \n",
    "    \"index\":[0],\\\n",
    "    \"data\":[[2596,51,3,258,0,510,221,232,148,6279,1,\\\n",
    "        0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,\\ \n",
    "        0,0,0,0,0,0,0,0,0,0,0,1,0,0,0,0,0,0,0,0,0,0,0,5.0]] }'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "79d9adcd-00f6-4e16-bb07-3ae09b3eb670",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'http_data' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[35], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m r \u001b[38;5;241m=\u001b[39mrequests\u001b[38;5;241m.\u001b[39mpost(url \u001b[38;5;241m=\u001b[39m url ,headers\u001b[38;5;241m=\u001b[39m headers, data\u001b[38;5;241m=\u001b[39m\u001b[43mhttp_data\u001b[49m)\n\u001b[1;32m      2\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mPredictions: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mr\u001b[38;5;241m.\u001b[39mtext\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m'\u001b[39m)\n",
      "\u001b[0;31mNameError\u001b[0m: name 'http_data' is not defined"
     ]
    }
   ],
   "source": [
    "r =requests.post(url = url ,headers= headers, data=http_data)\n",
    "print(f'Predictions: {r.text}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ce172c16-e679-43b7-831c-8a9aa81f4d50",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
